---
title: "Literature Review of Bayesian Linear Regression"
author: "Heather Anderson"
format:
  html:
    link-external-icon: true
    link-external-newwindow: true
course: Capstone Projects in Data Science
bibliography: references.bib
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
theme: cyborg
---

Bayesian linear regression (BLR) is a statistical approach that uses
Bayesian principles to model relationships between variables. It
combines prior knowledge with data to make predictions and handle
uncertainty in the estimates. Unlike traditional Frequentist methods,
BLR provides a probability-based approach for both estimating values and
making forecasts.

Linear regression itself is a key technique for predicting one variable
based on another by finding the best-fitting line that minimizes the gap
between what we predict and what actually happens [@noauthor_2021-ow].
This method is used in both Frequentist and Bayesian approaches and
forms the groundwork for more advanced analysis.

In Bayesian linear regression, Bayes' Theorem is used to update prior
beliefs about model parameters with new data, resulting in a posterior
distribution that reflects a range of possible values rather than a
single estimate [@Bayes1991-uo]. This method takes into account previous
knowledge and measures the uncertainty in predictions, giving a richer
and often more useful picture compared to the single-point estimates
from Frequentist approaches [@Koehrsen2018-ff].

The Bayesian Analysis Toolkit (BAT) provides a real-world application of
Bayesian methods, utilizing Markov Chain Monte Carlo (MCMC) techniques
for posterior sampling and model comparison. BAT allows for flexible
modeling and easy numerical integration, showing how Bayesian techniques
can be applied in practical situations [@Caldwell2009-bw].

Visualization plays a critical role in Bayesian workflows, as
highlighted by Gabry et al. [@Gabry2019-qz]. Tools such as trace plots
and Hamiltonian Monte Carlo (HMC) diagnostics are crucial for figuring
out if a model is working well and identifying any issues. In addition,
techniques like posterior predictive checks and leave-one-out (LOO)
cross-validation help fine-tune the model by testing how well it
predicts new data.

Zyphur and Oswald [@Zyphur2015-pz] compare Bayesian and Frequentist
methods, showing that Bayesian techniques often offer more dependable
results. They do this by incorporating prior knowledge and overcoming
some of the challenges that Frequentist methods face, especially with
small sample sizes. Their study highlights how Bayesian methods can
enhance predictions and help in better understanding the data.

Van de Schoot et al. [@Van_de_Schoot2021-hd] explore how Bayesian
statistics are becoming increasingly relevant and adaptable in today’s
research. They point out that, with the help of modern deep learning and
powerful computers, Bayesian methods are significantly improving the
analysis of complex data. For instance, techniques like variational
autoencoders, which combine Bayesian ideas with deep learning, are great
for managing high-dimensional data and making precise predictions. This
blend of Bayesian methods with advanced technology shows how Bayesian
analysis is evolving to tackle modern challenges and boost scientific
progress.

Gelman et al. [@Gelman2013-aj] offer a detailed look at Bayesian
methods, including how they apply to linear regression. They highlight
the advantages of using Bayesian approaches to handle uncertainty and
improve models by incorporating prior information, which in turn boosts
predictive accuracy and overall model performance.

Recent progress in variational inference, as highlighted by Blei,
Kucukelbir, and McAuliffe [@Blei2017-kg], offers scalable alternatives
to MCMC methods. Variational inference works by approximating posterior
distributions through optimization, making it a more efficient choice
for handling large datasets and complex models.

Carpenter et al. [@Carpenter2017-ul] focus on how Bayesian methods are
used in hierarchical models, particularly for complex systems. They
point out that Bayesian hierarchical modeling is especially useful for
handling data with multiple levels and capturing detailed relationships
between variables, which improves both the flexibility and the accuracy
of models in practical situations.

In conclusion, Bayesian linear regression is a powerful tool for
modeling and predicting how variables are related. It stands out because
it blends prior knowledge with a way to handle uncertainty. With the
help of advanced diagnostics, practical tools like BAT, and recent
breakthroughs in computing and deep learning, Bayesian methods show just
how flexible and effective they can be for analyzing complex data in
today’s world.
